# gender_classification_cnn

This is an implementation of CNN in Python using the Keras library for classifying men and women as part of the course Machine Vision.

### Dataset

The Dataset is taken from:

1. [The Yale Face Database](http://vision.ucsd.edu/~iskwak/ExtYaleDatabase/ExtYaleB.html)

Contains 5760 single light source images of 10 subjects each seen under 576 viewing conditions (9 poses x 64 illumination conditions). For every subject in a particular pose, an image with ambient (background) illumination was also captured.


2. [AT&T The Database of Faces](https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html)

There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement).


3. [The Japanese Female Facial Expression (JAFFE) Database](http://www.kasrl.org/jaffe.html)

The database contains 213 images of 7 facial expressions (6 basic facial expressions + 1 neutral) posed by 10 Japanese female models. Each image has been rated on 6 emotion adjectives by 60 Japanese subjects. The database was planned and assembled by Michael Lyons, Miyuki Kamachi, and Jiro Gyoba.

### Result

